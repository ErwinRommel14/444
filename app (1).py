import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="Disney Princess Classifier", layout="centered")
st.markdown("<h1 style='text-align: center; color: #333333;'>üéÄ Disney Princess Iconic Status Predictor</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; font-size: 18px;'>–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º, —Å—Ç–∞–Ω–µ—Ç –ª–∏ –ø—Ä–∏–Ω—Ü–µ—Å—Å–∞ –∫—É–ª—å—Ç–æ–≤–æ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ñ–∏–ª—å–º–∞.</p>", unsafe_allow_html=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_data():
    url = "disney_princess_popularity_dataset_300_rows.csv"
    return pd.read_csv(url)

try:
    data = load_data()
except:
    st.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ.")
    data = pd.DataFrame({
        'NumberOfSongs': [4, 1, 3, 5],
        'HasSoloSong': ['Yes', 'No', 'Yes', 'No'],
        'BoxOfficeMillions': [500, 300, 700, 200],
        'IMDB_Rating': [7.5, 6.8, 8.2, 6.5],
        'IsIconic': ['Yes', 'No', 'Yes', 'No']
    })

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
def preprocess_data(df):
    df = df.copy()

    binary_map = {'Yes': 1, 'No': 0}
    binary_cols = ['HasSoloSong', 'HasDuet', 'IsRoyalByBirth', 'HasAnimalSidekick',
                  'HasMagicalPowers', 'SpeaksToAnimals', 'FightsVillainDirectly', 'IsIconic']

    for col in binary_cols:
        if col in df.columns:
            df[col] = df[col].map(binary_map).fillna(0)

    num_cols = ['NumberOfSongs', 'BoxOfficeMillions', 'IMDB_Rating', 'MovieRuntimeMinutes']
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    return df

data_processed = preprocess_data(data)

# –í—ã–±–æ—Ä —Ñ–∏—á–µ–π
default_features = ['NumberOfSongs', 'HasSoloSong', 'BoxOfficeMillions', 'IMDB_Rating']
available_features = [col for col in default_features if col in data_processed.columns]

if not available_features:
    st.error("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.")
    st.stop()

X = data_processed[available_features]
y = data_processed.get('IsIconic', pd.Series(np.zeros(len(data_processed))))

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
except:
    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
    st.stop()

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def train_models():
    models = {}

    try:
        lr = LogisticRegression(max_iter=1000)
        lr.fit(X_train_scaled, y_train)
        models['Logistic Regression'] = lr
    except Exception as e:
        st.warning(f"Logistic Regression error: {str(e)}")

    try:
        rf = RandomForestClassifier()
        rf.fit(X_train, y_train)
        models['Random Forest'] = rf
    except Exception as e:
        st.warning(f"Random Forest error: {str(e)}")

    return models

models = train_models()

if not models:
    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
    st.stop()

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
st.markdown("### üé´ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏–Ω—Ü–µ—Å—Å—ã")
def get_user_input():
    inputs = {}

    if 'NumberOfSongs' in available_features:
        inputs['NumberOfSongs'] = st.slider("üéµ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Å–µ–Ω", 0, 10, 3)

    if 'HasSoloSong' in available_features:
        inputs['HasSoloSong'] = st.radio("üé§ –°–æ–ª—å–Ω–∞—è –ø–µ—Å–Ω—è?", ["No", "Yes"]) == "Yes"

    if 'BoxOfficeMillions' in available_features:
        inputs['BoxOfficeMillions'] = st.slider("üí∞ –ö–∞—Å—Å–æ–≤—ã–µ —Å–±–æ—Ä—ã ($ –º–ª–Ω)", 0, 2000, 500)

    if 'IMDB_Rating' in available_features:
        inputs['IMDB_Rating'] = st.slider("‚≠ê –†–µ–π—Ç–∏–Ω–≥ IMDB", 0.0, 10.0, 7.0)

    return pd.DataFrame([inputs])

user_input = get_user_input()

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–≤–æ–¥–∞
st.markdown("### üìã –í–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
st.dataframe(user_input.style.highlight_max(axis=0))

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

model_choice = st.selectbox("üß† –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", list(models.keys()))

if st.button("üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—É—Å"):
    model = models[model_choice]

    try:
        if model_choice == 'Logistic Regression':
            input_scaled = scaler.transform(user_input)
            prediction = model.predict(input_scaled)
            proba = model.predict_proba(input_scaled)
        else:
            prediction = model.predict(user_input)
            proba = model.predict_proba(user_input)

        result = "üåü –ò–∫–æ–Ω–Ω–∞—è" if prediction[0] == 1 else "üí´ –ù–µ –∏–∫–æ–Ω–Ω–∞—è"
        probability = f"{max(proba[0]) * 100:.1f}%"

        # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
        st.markdown(f"""
        <div style='background-color:#eaeaea;padding:12px;border-radius:10px;text-align:center;'>
            <h3 style='color:#333;margin:0;'>{result}</h3>
            <p style='margin:5px 0;font-size:14px;'>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: <strong>{probability}</strong></p>
        </div>
        """, unsafe_allow_html=True)

        # –ú–∞–ª–µ–Ω—å–∫–∏–π –≥—Ä–∞—Ñ–∏–∫
        fig, ax = plt.subplots(figsize=(3, 2))
        sns.barplot(x=['–ù–µ –∏–∫–æ–Ω–Ω–∞—è', '–ò–∫–æ–Ω–Ω–∞—è'], y=proba[0], palette="Blues_r", ax=ax)
        ax.set_ylabel("")
        ax.set_xlabel("")
        ax.tick_params(axis='both', which='major', labelsize=8)
        plt.tight_layout()

        st.pyplot(fig)

    except Exception as e:
        st.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
st.markdown("### üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π")
metrics = []
for name, model in models.items():
    if name == 'Logistic Regression':
        y_pred = model.predict(X_test_scaled)
    else:
        y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    metrics.append({"–ú–æ–¥–µ–ª—å": name, "–¢–æ—á–Ω–æ—Å—Ç—å": f"{acc:.2%}"})

st.table(pd.DataFrame(metrics).style.set_properties(**{'text-align': 'center'}))

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if 'Random Forest' in models:
    st.markdown("### üß© –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest)")

    try:
        importances = models['Random Forest'].feature_importances_
        feat_importances = pd.Series(importances, index=available_features)
        fig, ax = plt.subplots(figsize=(4, 2))
        feat_importances.nlargest(10).plot(kind='barh', ax=ax, color="#4682B4")
        ax.tick_params(axis='both', which='major', labelsize=8)
        ax.set_title("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", fontsize=10)
        plt.tight_layout()
        st.pyplot(fig)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–∫–∞–∑–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {str(e)}")

# –°–æ–≤–µ—Ç—ã –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
st.markdown("### üí° –ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–∏–Ω—Ü–µ—Å—Å—É –∏–∫–æ–Ω–∏—á–µ—Å–∫–æ–π?")
st.markdown("""
- üé∂ –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –ø–µ—Å–µ–Ω
- üé§ –î–∞–π—Ç–µ –µ–π —Å–æ–ª—å–Ω—É—é –∫–æ–º–ø–æ–∑–∏—Ü–∏—é
- üí∞ –°—Ç—Ä–µ–º–∏—Ç–µ—Å—å –∫ –≤—ã—Å–æ–∫–∏–º —Å–±–æ—Ä–∞–º (> $500 –º–ª–Ω)
- ‚≠ê –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ä–µ–π—Ç–∏–Ω–≥ –≤—ã—à–µ 7.5
""")

# –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
st.markdown("""
<style>
    .stButton button {
        background-color: #4682B4;
        color: white;
        border-radius: 6px;
        padding: 10px 20px;
        font-weight: bold;
    }
    .stDataFrame {
        font-size: 14px;
    }
</style>
""", unsafe_allow_html=True)